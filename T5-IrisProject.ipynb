{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "594aa91e-339e-4d6b-b401-6636c57fcc9e",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "- Load the Iris dataset.\n",
    "- Perform data exploration and visualization.\n",
    "- Check for missing values and handle them if any.\n",
    "- Split the dataset into features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4156c12-f7d2-4d30-93f4-4803d346beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neccesary libraries:-\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b99c2-1c21-44c8-a4ca-9f65d96de8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc917ca4-ebd6-4d81-bdfd-7b78cffb09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f21911-cb88-44d4-bb7c-5b4e7f0dd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the total missing values in the dataset:\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f558c79-e720-4fa9-bd20-fd15e797c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column name into meaningful names:\n",
    "df.rename(columns={'Column1':'SepalLengthCm', 'Column2':'SepalWidthCm', 'Column3':'PetalLengthCm','Column4':'PetalWidthCm','Column5':'Species'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5755161-a84b-4f65-a5d1-f28040d8bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa646e7-1911-44e4-a7df-90982bbdea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4dba36-177b-4cb6-ba89-59ea5dd1dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588345a3-a9b7-47d2-aa53-c8d0b2158edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713c170-ba3c-4d05-a1b5-40fad5421cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train set and test set:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07ed17-cc48-4483-bfd6-d00a6fd1f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of the train data:', 'X_train:',X_train.shape,'y_train:', y_train.shape)\n",
    "print('The shape of the test data:', 'X_test:', X_test.shape,'y_test:', y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f82f7-183b-4175-9712-3e93a5fa3336",
   "metadata": {},
   "source": [
    "## Unsupervised Learning: Clustering and Outlier Detection:\n",
    "- Apply K-means clustering algorithm to cluster the data.\n",
    "- Visualize the clusters.\n",
    "- Detect outliers using appropriate techniques such as isolation forest or DBSCAN.\n",
    "- Evaluate the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3bedd-8aa5-4af7-90a6-ce9a2668f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import kmeans library\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "k_means = KMeans(n_clusters=3)\n",
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451a9e4-5592-41f3-9548-1d026da67176",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[df.Species=='Iris-setosa'].plot.scatter(x='SepalLengthCm', y='SepalWidthCm', \n",
    "                                                    color='red', label='Iris - Setosa')\n",
    "df[df.Species=='Iris-versicolor'].plot.scatter(x='SepalLengthCm', y='SepalWidthCm', \n",
    "                                                color='green', label='Iris - Versicolor', ax=ax)\n",
    "df[df.Species=='Iris-virginica'].plot.scatter(x='SepalLengthCm', y='SepalWidthCm', \n",
    "                                                color='blue', label='Iris - Virginica', ax=ax)\n",
    "ax.set_title(\"Scatter Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352ef67-6ec2-4f78-8a17-fb80e002a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sepal_length = df.loc[:, ['SepalLengthCm']]\n",
    "X_sepal_width = df.loc[:, ['SepalWidthCm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f26bba-65d0-4e5a-b27f-c73818fce1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cluster with n_clusters = 2 for the sepal length & sepal width\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x= X_sepal_length['SepalLengthCm'], y=X_sepal_width['SepalWidthCm'], c=k_means.labels_)\n",
    "plt.xlabel('SepalLengthCm')\n",
    "plt.ylabel('SepalWidthCm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a1006-26e1-4fbf-82ee-d9a5dcfebba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Petal_length = df.loc[:, ['PetalLengthCm']]\n",
    "y_Petal_width = df.loc[:, ['PetalWidthCm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f94293-71a4-443f-9e03-168132df1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cluster with n_clusters = 2 for the petal length & petal width\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x= y_Petal_length['PetalLengthCm'], y=y_Petal_width['PetalWidthCm'], c=k_means.labels_)\n",
    "plt.xlabel('PetalLengthCm')\n",
    "plt.ylabel('PetalWidthCm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b1af0-dec6-4ce1-8571-df2368e08958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing vaules using DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "DBSModel = DBSCAN(metric='euclidean',eps=0.0375, min_samples=20, algorithm='auto')\n",
    "y_pred_train = DBSModel.fit_predict(X_train)\n",
    "y_pred_test = DBSModel.fit_predict(X_test)\n",
    "\n",
    "print('DBScanModel labels are:', DBSModel.labels_)\n",
    "print('DBScanModel Train data are:', y_pred_train)\n",
    "print('DBScanModel Test data are:', y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60959fd4-7baf-4aed-ad64-7761ce9412f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclusters = len(set(DBSModel.labels_)) - (1 if -1 in DBSModel.labels_ else 0)\n",
    "n_noise = list(DBSModel.labels_).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % nclusters)\n",
    "print('Estimated number of noises: %d' % n_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289febea-ab1d-4403-9f66-c67a82651c6b",
   "metadata": {},
   "source": [
    "## Supervised Learning: Baseline Model:\n",
    "- Choose an appropriate evaluation metric based on the problem (classification)\n",
    "- Split the dataset into training and testing set.\n",
    "- Build a baseline model (e.g., logistic regression or decision tree) using default parameter.\n",
    "- Evaluate the baseline model's performarmance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9062881-49b2-4a13-b870-f65280bdeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "evaluation_metric = 'accuracy'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "baseline_model = LogisticRegression()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "evaluation_result = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Model Performance ({evaluation_metric}): {evaluation_result}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e5b2e-1d71-4662-b60d-369e1991a7fc",
   "metadata": {},
   "source": [
    "## Model Comparison:\r",
    "- Select 3-4 machine learning algorithms (e.g., SVM, Random Forest, Gradient Boosting) suitable for the problem.\n",
    "- Implement each algorithm and evaluate its performance using cross-validation\n",
    "- Compare the performance of algorithms based on evaluation metrics\n",
    "- Select the best-performing algorithm.\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0cdbd-7b27-409d-aa8d-78812545a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "evaluation_metric = 'accuracy'\n",
    "num_folds = 5\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring=evaluation_metric)\n",
    "    results[model_name] = scores\n",
    "\n",
    "print(\"Mean {} Scores:\".format(evaluation_metric))\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name}: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e478e4-b336-425d-96de-3a326b1c4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model based on the performance:\n",
    "best_model = max(results, key=lambda x: np.mean(results[x]))\n",
    "print(\"\\nBest Performing Model:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8f802-64e6-4856-9de4-bf404e251969",
   "metadata": {},
   "source": [
    "## Model Tuning and Ensemble:\n",
    "-  Perform hyperparameter tuning on the best-performing algorithm using Grid Search or Random Search\n",
    "- • Evaluate the tuned model's performan.\n",
    "-  • Implement an ensemble of the top-performing algorithms and compare its performance with the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddf6c6-d987-4e25-a4cd-3e8d543e38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_clf = SVC()\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_clf, param_grid_svm, cv=num_folds, scoring=evaluation_metric)\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_score_svm = grid_search_svm.best_score_\n",
    "\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Best mean accuracy score for SVM:\", best_score_svm)\n",
    "\n",
    "tuned_svm_predictions = best_svm_model.predict(X_test)\n",
    "accuracy_tuned_svm = accuracy_score(y_test, tuned_svm_predictions)\n",
    "print(\"Accuracy of the tuned SVM model:\", accuracy_tuned_svm)\n",
    "\n",
    "\n",
    "ensemble_models = [\n",
    "    ('Tuned SVM', best_svm_model),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "ensemble = VotingClassifier(estimators=ensemble_models, voting='hard')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "ensemble_predictions = ensemble.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(\"Accuracy of the ensemble model:\", accuracy_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a87da-0261-432b-9430-04c92681b486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
